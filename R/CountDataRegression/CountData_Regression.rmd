---
title: <span style="color:black">"Count Data Regression- by Shadab Kalim"</span>
output:
  word_document: default
  html_document:
    df_print: paged
---

Install the libraries to be used

```{r setup}

if (!require(MASS)){install.packages("MASS")}
if (!require(corrplot)){install.packages("corrplot")}
if (!require(forecast)){install.packages("forecast")}
if (!require(psych)){install.packages("psych")}
if(!require(dplyr)){install.packages("dplyr")}
if(!require(tidyverse)){install.packages("tidyverse")}
if(!require(corrplot)){install.packages("corrplot")} 
if(!require(AER)){install.packages("AER")} 
if(!require(splines)){install.packages("splines")} 
if(!require(survival)){install.packages("survival")} 


library(MASS)
library(corrplot)
library(forecast)
library(psych)
library(dplyr)
library(tidyverse)
library(AER)
library(splines)
library(survival)
```
## <span style="color:blue">A. Beluga Whale Calves at the Aquarium for Wildlife Conservation: </span>

Read the csv file with lock on data to R data and seggregate datasets for Hudson and Casey:

```{r read file}
whales.df <- read.csv(file.choose(), stringsAsFactors =FALSE)

colnames <- c("Period","Bouts","Lockons","Daytime")
lockonsHudson.df <- cbind(whales.df$Period.Hudson,whales.df$Bouts.Hudson,whales.df$Lockons.Hudson,whales.df$Daytime.Hudson)
colnames(lockonsHudson.df) <- colnames
lockonsCasey.df <- cbind(whales.df$Period.Casey,whales.df$Bouts.Casey,whales.df$Lockons.Casey,whales.df$Daytime.Casey)
colnames(lockonsCasey.df) <- colnames
lockonsHudson.df <- data.frame(lockonsHudson.df)
lockonsCasey.df <- data.frame(lockonsCasey.df)
lockonsHudson.df$Daytime <-as.factor(lockonsHudson.df$Daytime)
lockonsCasey.df$Daytime <-as.factor(lockonsCasey.df$Daytime)

```

### <span style="color:blue">A 1. Obtain summary statistics for the two whale calves, Hudson and Casey and make comparative statement. </span>

Based on the summary statistics and plots below, we can clearly see the following -

1. The number of zeros in the lockons data for Hudson and casey are low.
2. The mean and variances for both Hudson and Casey for Lockons are significantly different (variance is about 5 times of mean).
3. There is significant difference in mean lockons for Hudson and Casey. Hudson has significantly lower mean lockons for slightly lower mean bouts and Casey has significantly higher mean lockons for slightly higher mean bouts.
4. The mean and median is roughly same for lockons for both Hudson and Casey suggestive not many outliers as can be seen in box plots (5 outliers for Hudson and 3 for casey for Lockons).
5. The summary statistics suggests few NAs for Casey (5) and none for Hudson, upon closer examination of original data set we find that for Hudson we have 5 rows more than Casey. So i have removed NAs from Casey dataset.
6. The mean values for Bouts and Lockons for day and night for both Hudson are Casey are near about same, suggestive of no clear preference for Day or Night time for Bouts and Lockons i.e. this variable is likely to be insignificant.
7. There is strong positive correlation between Bouts and Lockons for both Hudson and Casey which is expected, however there is a weak negative correlation between Period and Lockons for Casey which suggests a drop in Lockons with increasing periods for Casey which i guess is natural as the calf will eventually move away from mothers milk so this is a good sign for Casey but for Hudson it suggests longer nursing period as correlationis-0.04.

```{r get summary statistics}
print("Summary Statistics for Hudson")
stat.desc(lockonsHudson.df, basic=TRUE, desc=TRUE)

print("Summary Statistics for Casey")
stat.desc(lockonsCasey.df, basic=TRUE, desc=TRUE)

print("Mode of Lockons for Hudson")
y <- table(lockonsHudson.df$Lockons)
names(y)[which(y==max(y))]

print("Mode of Lockons for Casey")
y <- table(lockonsCasey.df$Lockons)
names(y)[which(y==max(y))]

lockonsHudson.df %>% tally() # row count
lockonsCasey.df %>% tally() # row count

print("Means by Day time")
lockonsHudson.df %>%  group_by(Daytime) %>%  summarise_all(mean, na.rm=TRUE)
lockonsCasey.df %>%  group_by(Daytime) %>%  summarise_all(mean, na.rm=TRUE)
#lockonsHudson.df %>% count(Lockons, sort = TRUE) %>% arrange(Lockons)
#lockonsCasey.df %>% count(Lockons, sort = TRUE) %>% arrange(Lockons)

plot(table(lockonsHudson.df$Lockons), main="Lockon frequency - Hudson",xlab="No of Lockons - Hudson", ylab="Frequency")
plot(table(lockonsCasey.df$Lockons), main="Lockon frequency - Casey",xlab="No of Lockons - Casey", ylab="Frequency")
lockonsCasey.df <- na.omit(lockonsCasey.df)

print("Correlation plot for Hudson")
M <- cor(lockonsHudson.df[,1:3])
corrplot(M, method = "number")

print("Correlation plot for Casey")
M <- cor(lockonsCasey.df[,1:3])
corrplot(M, method = "number")

boxplot(lockonsHudson.df[,1:3], horizontal=TRUE, main="Box plot of all variables - Hudson")
boxplot(lockonsCasey.df[,1:3], horizontal=TRUE, main="Box plot of all variables - Casey")

```

### <span style="color:blue">A 2. Make comparative statements on the underlying probability distributions of the number of lockons of the two calves. With justification, propose appropriate regression model for number of lockons for each data set.</span>

The underlying distributions for lockons for Hudson is right skewed similar to Poison PMF with labda near 5 and Casey is slightly right skewed but closer to normal (has higher mean at 27) similar to Poison PMF with lambda between 10 - 20, this is also evident from mode, median and mean value of 22,25 and 27 respectively for Casey. The distributions suggest trying out a Poison regression model. We can compare the distributions to the Poison PMF plots for different lambdas as shown below (Plot taken from - http://www.efunda.com/math/distributions/PoissonDistPlot.cfm) -

```{r Plot lockon distribution}
par(mfrow=c(1, 1))
colnames <- c("LockOns Hudson", "LockOns Casey")
locombined.df <- cbind(lockonsHudson.df$Lockons, lockonsCasey.df$Lockons)
colnames(locombined.df) <- colnames
locombined.df <- data.frame(locombined.df)

for (i in 1:2) {
    hist(locombined.df[,i], xlim=c(0, 100), breaks=seq(0, 100, 5), main=colnames[i], probability=TRUE, col="gray", border="white")
    d <- density(locombined.df[,i])
    lines(d, col="red")
}

```

```{r pressure, echo=FALSE, fig.cap="A caption", out.width = '100%'}
knitr::include_graphics("Poison_Dist.png")
```
### <span style="color:blue">A 3. For each data set, construct the regression model you have proposed in (2) above for the number of lockons in each period as a function of time, number of nursing bouts, and time of the day. Interpret your results.</span>

I first fitted the Poisson model. The Poisson model a high residual deviance compared to degrees of freedom for both Hudson and Casey (nealy double and negligible p value for both) and the overdispersion test is suggestive of overdispersion for both Hudson and casey which are indicative of a poor fit for Poisson model. 
Below is an analysis of the diagnostic plots -

Hudson dataset-
The Residuals vs the fitted plot is not random but more concentrated in center indicative of poor fit.
The Normal QQ plot shows a skewed distribution.
The Scale location plot shows unequal dispersion suggestive of over dispersion.
Residuals vs Leverage plot shows some influential values like row nos-86, 196,213. 

Casey Dataset-
The Residuals vs the fitted plot is not random but more concentrated in center indicative of a poor fit.
The Normal QQ plot shows a better fit than Hudson dataset but still a skewed distribution.
The Scale location plot shows unequal dispersion suggestive of over dispersion.
Residuals vs Leverage plot shows some influential values like row nos-137, 143, 219

```{r Poisson Model Fitting }
# Fitting Poison
fm_poisHudson <- glm(Lockons ~ Period + Bouts + Daytime, data = lockonsHudson.df, family = poisson)
summary(fm_poisHudson)
dispersiontest(fm_poisHudson,trafo = 1)

anova(fm_poisHudson)
par(mfrow=c(1,1))
plot(fm_poisHudson)
par(mfrow=c(1,1))
with(fm_poisHudson,cbind(res.deviance=deviance, df=df.residual,p=pchisq(deviance, df.residual, lower.tail=FALSE)))

fm_poisCasey <- glm(Lockons ~ Period + Bouts + Daytime, data = lockonsCasey.df, family = poisson)
summary(fm_poisCasey)
dispersiontest(fm_poisCasey,trafo = 1)

anova(fm_poisCasey)
par(mfrow=c(1,1))
plot(fm_poisCasey)
par(mfrow=c(1,1))
with(fm_poisCasey,cbind(res.deviance=deviance, df=df.residual,p=pchisq(deviance, df.residual, lower.tail=FALSE)))
```

### <span style="color:blue">A 4.1. Do the variables provide predictive power? Justify.</span>

Model fit statistic R -square - 

For Hudson = 1- (Residual Deviance of full model)/(Residual deviance of the null model) = 1 - (571.65)/1213 = 0.528, shows that the model accounts for half the deviance in number of lockons for Hudson.

For Casey = 1- (Residual Deviance of full model)/(Residual deviance of the null model) = 1 - (461.15)/1061.86 = 0.565, shows that the model accounts for slightly more than half the deviance in number of lockons for Casey.

Looking at regression output after fitting the Poisson model for Hudson and Casey, we can see that the Coefficients for Bouts and Periods variable are statistically significant for both whale calf's. Daytime variable is not significant for both calf's as was evident from point 6 under Question 1. 

So the variables Bouts and Periods do have predictive power as was seen from correlation matrix plot as well.

### <span style="color:blue">A 4.2. How would you interpret the coefficient for time period for the model?</span>

As only Periods and Bouts are statistically significant, As Poisson regresson model is log-link model, For the Hudson dataset, the coefficient of time (Period) can be interpereted as the expected log(number of lockons) for one time period (6 Hrs) increase in period is -0.0008701 and so the ratio of number of lockons at time period x + 1 (6 Hrs) to time period x is exp(-0.0008701) ~ 0.99913 when Bouts is kept constant - meaning a decrease of 0.09% in lockons in each subsequent time period if Bouts is held constant for each unit increase in Period.

For the Casey dataset, the coefficient of time (Period) can be interpereted as the expected log(number of lockons) for one time period (6 Hrs) increase in period is -0.0011639 and so the ratio of number of lockons at time period x + 1 (6 Hrs) to time period x is exp(-0.0011639) ~ 0.99884 when Bouts is kept constant - meaning a decrease of 0.12% in lockons in each subsequent time period if Bouts is held constant for each unit increase in Period.

### <span style="color:blue">A 4.3. Does this model suffer from over dispersion? Justify with appropriate analysis. If the selected model suffers from over dispersion, propose and fit an alternative model which will take care of over dispersion.</span>

The Poisson model i have fitted does suffer from overdispersion for both Hudson and Casey datasets. This justified by the overdispersion test result of negligible p-values as shown below - 

For Hudson - 
data:  fm_poisHudson
z = 5.571, p-value = 1.266e-08

For Casey - 
data:  fm_poisCasey
z = 4.4633, p-value = 4.035e-06

Also the Scale location plot for both the datasets shows unequal dispersion suggestive of over dispersion.

As the number of 0 count for lockons is low for both the datasets, it can be assumed that the overdispersion is not due to excess zeros and more due to heterogeneity of population, to accomodate overdispersion i propose the Negative Binomial model.

Next I fitted a negative binomial model to account for overdispersion by treating the parameter µ itself as a random
variable. i.e. instead of modeling Yi as Poisson(µi) we model Yi|µi ??? Poisson(µi) where µi are random varibles distributed as Gamma with parameters ??i, ????i. This approach leads to Yi following Negative Binomial distribution.

```{r Negative Binomial Regression Model Fitting}
fm_nbinHudson <- MASS::glm.nb(Lockons ~ Period + Bouts + Daytime, data = lockonsHudson.df)
summary(fm_nbinHudson)
anova(fm_nbinHudson)
par(mfrow=c(1,1))
plot(fm_nbinHudson)
par(mfrow=c(1,1))
with(fm_nbinHudson,cbind(res.deviance=deviance, df=df.residual,p=pchisq(deviance, df.residual, lower.tail=FALSE)))

fm_nbinCasey <- MASS::glm.nb(Lockons ~ Period + Bouts + Daytime, data = lockonsCasey.df)
summary(fm_nbinCasey)
anova(fm_nbinCasey)
par(mfrow=c(1,1))
plot(fm_nbinCasey)
par(mfrow=c(1,1))
with(fm_nbinCasey,cbind(res.deviance=deviance, df=df.residual,p=pchisq(deviance, df.residual, lower.tail=FALSE)))


```
### <span style="color:blue">A 4.4. Does this alternative model have different implications than the initial model you selected in (3) above? Is it a better fit to the data? Justify your answer with proper analysis.</span>

The Negative Binomial model provides different implications. Negative binomial regression could be used when the conditional variance exceeds the conditional mean. It can be considered as a generalization of Poisson regression since it has the same mean structure and it has an extra parameter to model the over-dispersion. If the conditional distribution of the outcome variable is over-dispersed, the confidence intervals for the Negative binomial regression are likely to be narrower as compared to those from a Poisson regression model. A Negative Binomial distribution introduces dependence of events which could couter overdispersion in Poisson if count data violates the assumption if independence between events. Here according to Negative Binomial model only the Bouts variable is statistically significant for the Hudson dataset and both Bouts and Period variables are statistically significant for Casey dataset which is perfectly in sync with the correlation matrix's for both the datasets (refer point 7 above), a possible indication of a better fit.

After fitting the Negative Binomial model to both the datasets, the following obeservations appear - 

Hudson dataset-

The negative binimial model gives a much lower residual deviance compared to Poisson which is near to residual degrees of freedom and the p-value for Goodness of fit is also acceptable at 0.07. The AIC value is also lower compared to Poisson model.

Plots analysis-
The Residuals vs the fitted plot is not entirely random but somewhat concentrated in center indicative of average fit.
The Normal QQ plot shows a decent plot with most values in straight line with some values deviating.
The Scale location plot shows less over dispersion.
Residuals vs Leverage plot shows some outliers like row nos-196,213 etc.

Casey Dataset-

The negative binimial model gives a much lower residual deviance compared to Poisson which is near to residual degrees of freedom though the p-value for Goodness of fit is low at 0.02. The AIC value is also lower compared to Poisson model.

Plots analysis-
The Residuals vs the fitted plot is not entirely random but somewhat concentrated in center indicative of average fit.
The Normal QQ plot shows a decent plot with most values in straight line with some values deviating.
The Scale location plot shows less over dispersion.
Residuals vs Leverage plot shows some outliers like row nos-137,219

Overall negative binomial model fits the lockons count data better accounting for overdispersion to some extent.

### <span style="color:blue">A 5. Using the two models for two calves you have finally selected, make comparative statements on how the predictors are affecting the number of lockons.</span>

Hudson Dataset - 
For this dataset the final model using Negative Binomial suggests that only Bouts variable is statistically significant (this fits well with correlation matrix also). The coefficient of 0.1350092 for Bouts suggests that on an average for a unit increase in Bouts the lockons increase by 14.5% (exp(0.1350092) ~ 1.145). The model clearly picks Bouts are having maximum affect on Lockons for Hudson.

Model fit statistic R -square - 
For Hudson = 1- (Residual Deviance of full model)/(Residual deviance of the null model) = 1 -(255.69/540.62) = 0.528, shows that the model accounts for half the deviance in number of lockons for Hudson.

Casey Dataset - 
For this dataset the final model using Negative Binomial suggests that both Period and Bouts variable to be statistically significant (this fits well with correlation matrix also). The coefficient of -0.0010278 for Period suggests that on an average for a unit increase in Period, the lockons decrease by 0.1% if Bouts is held constant (exp(-0.0010278) ~ 0.99897), the coefficient of 0.0980853 for Bouts suggests that on an average for a unit increase in Bout, the lockons increase by 10.3% if Periods is held constant (exp(0.0980853) ~ 1.1031). The model clearly picks Periods and Bouts both to be having maximum affect on Lockons for Casey with Bouts having more prominent affect.

Model fit statistic R -square - 
For Casey = 1- (Residual Deviance of full model)/(Residual deviance of the null model) = 1 - (262.33/583.74) = 0.55, shows that the model accounts for slightly more than half the deviance in number of lockons for Casey.

### <span style="color:blue">B 1. Explore the data. What is the basic difference you are noticing between the two groups?</span>


```{r read leukemia.csv}
leukemia.df <- read.csv(file.choose(), stringsAsFactors =FALSE)
```

Looking at data grouping based on treatment, status (censored or failure) and sex we find that all of the patients who took standard treatment therapy (group 1) had a failure status 1 indicating event of interest (replase or death) (10 + 11) whereas only 9 patients had a failure status 1 with 12 having censored status in group which took new treatment (group 2). Thus possibily indicative of different survival rates between the groups. 
Also the number of females and males who took new treatment and censored is same at 6, the number is also nearly same for those took new treatment and had failure status ( 5 and 4), indicating Survival curves are same between sexes.

I performed the log rank test to check if the survival curve is significantly different between the two groups (new treatment therapy vs standard treatment therapy).
As the p - value is very small the survival curve is significantly different between the two groups (based on treatment) its  suggestive of different survival rates which appears to be the basic difference as evident from data gouping analysis.

Next we repeat the same log rank test to check if the survival curves are different between Sexes (males vs females). The p-value of this log rank test is high (0.7) indicating that the survival curves are not different but similar between Sexes as suggested by data grouping.

```{r Log Rank}
grouped_data <- aggregate(leukemia.df, by=list(leukemia.df$Rx, leukemia.df$status, leukemia.df$sex), FUN=length)
colnames(grouped_data)[colnames(grouped_data)=="Group.1"] <- "Treatment"
colnames(grouped_data)[colnames(grouped_data)=="Group.2"] <- "Status"
colnames(grouped_data)[colnames(grouped_data)=="Group.3"] <- "Sex"
colnames(grouped_data)[colnames(grouped_data)=="survival.times"] <- "Count"
grouped_data[, 1:4]
# Log Rank For treeatment
leukemia.df$sex <-as.factor(leukemia.df$sex)
leukemia.df$Rx <-as.factor(leukemia.df$Rx)
log_rank=survdiff(Surv(leukemia.df$survival.times,leukemia.df$status)~leukemia.df$Rx,rho=1)
log_rank
# Log Rank For sex of patients
log_rank=survdiff(Surv(leukemia.df$survival.times,leukemia.df$status)~leukemia.df$sex,rho=1)
log_rank
```

### <span style="color:blue">B 2. Compute Kaplan-Meier estimate of survival function and Nelson-Allen estimates of cumulative hazard rate.</span>

```{r}
stud.Model <- glm(HighAchievers ~ 
                    AGE + 
                    factor(Gender) +
                    factor(CASTE) +
                    factor(RELIGN) +
                    factor(MTONGUE) +
                    factor(OCCU) +
                    INCOME +
                    AREA_Agrl,
                  data=stud1, 
                  family = "binomial")   
```

Check Residuals and Coefficients (log coeffs) in the model

```{r}
summary(stud.Model) 

#To get actual coefficients
exp(coef(stud.Model)) 
```

We need to check how accurate the model is working. We will predict the HighAchievers using the Full model for the same sample

We need to build the Confusion matrix
```{r}
stud_pred <- predict(stud.Model, newdata = stud1, type = "response")
stud_pred <- as.numeric(stud_pred>0.5)
table(stud_pred,stud1$HighAchievers)
(stud_pred)
```

We need to prepare ROC curve for fundamental diagnostic test evaluation

```{r}
## ROC curve
stud_pred <- predict(stud.Model, newdata = stud1, type = "response")
roccurve <- roc(stud1$HighAchievers ~ stud_pred)

#To plot ROC
plot(roccurve)             
```

We need to see how much are is under the curve. Closer the area to 1, it is the better
```{r}
auc(stud1$HighAchievers, stud_pred)
```

Stepwise variable Selection
We have taken all the columns in Full model and we will go ahead with step wise analysis to see which variable contributes more.

```{r}

step.stud.model <- stud.Model %>% stepAIC(trace = TRUE)

coef(step.stud.model)

```

We can observe that INCOME column is the most contributive variable in the dataset.

We will compare full and step wise logistic models. Below is the prediction accuracy of Full Model

```{r}
fullprobabilities <- predict(stud.Model, stud1, type = "response")
fullpredicted.classes <- ifelse(fullprobabilities > 0.5, 1, 0)
# Prediction accuracy
fullobserved.classes <- stud1$HighAchievers
mean(fullpredicted.classes == fullobserved.classes)

```

Below is the prediction accuracy of model built from step wise regression -

```{r}
stepprobabilities <- predict(step.stud.model, stud1, type = "response")
steppredicted.classes <- ifelse(stepprobabilities > 0.5, 1, 0)
# Prediction accuracy
stepobserved.classes <- stud1$HighAchievers
mean(steppredicted.classes == stepobserved.classes)
```

Step wise logistic model's perfomance (with INCOME variable) is similar to the full model 
We will go with step wise model for prediction since it is less complex model giving results without compromising on accuracy.


Logistic Regression Diagnostics

Linearity Assumption (On Quantitative variables)

```{r}

stud1num <- stud1[,c(2:9)]
  
  #select(stud1,Gender.F.Female., AGE, CASTE, RELIGN, MTONGUE, OCCU, INCOME, AREA.Aggl.)

mydatastud1 <- stud1num %>%
  dplyr::select_if(is.numeric) 
predictors <- colnames(mydatastud1)


mydatastud1 <- mydatastud1 %>%
  mutate(logit = log(fullprobabilities/(1-fullprobabilities))) %>%
  gather(value = "predictor.value", key = "predictors",  -logit)

#Create scatterplots
ggplot(mydatastud1, aes(logit, predictor.value))+
  geom_smooth(method = "loess") + 
  geom_point(size = 0.5, alpha = 0.5) +
  facet_wrap(~predictors, scales = "free_y") + 
theme_bw()

```


Influential Values

Below are the top 3 extreme data points (Calculated using Cook's distance)

```{r}
plot(stud.Model, which = 4, id.n = 3)

stud.model.data <- augment(stud.Model) %>% 
  mutate(index = 1:n()) 
```

Top 3 values in tabluar format

```{r}
stud.model.data %>% top_n(3, .cooksd)
```


Below is the plot for standardized residuals:

```{r}
ggplot(stud.model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = HighAchievers), alpha = .5) +
  theme_bw()
```


To see if there are any influential data points (abs(.std.res) > 3)

```{r}
stud.model.data %>% 
  filter(abs(.std.resid) > 3)
```

There are no influential data points/observations in our data.